{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU training and model fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA\n",
    "\n",
    "PyTorch relies on CUDA for Nvidia GPUs to perform fast tensor operations.\n",
    "FYI, there is also ROCm support for AMD GPUs, but I've never tried it, so I don't know how well it works.\n",
    "\n",
    "In order to train your model on a Nvidia GPU, you need to:\n",
    "- Install the required CUDA drivers (check here https://pytorch.org/ which ones are supported by the last stable Pytorch version)\n",
    "- Install Pytorch with CUDA support (same link)\n",
    "- Mount tensors to GPU using `tensor.to(\"cuda\")` or `tensor.cuda()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 16\n",
    "lr = 1e-3\n",
    "n_epochs = 100\n",
    "train_val_split = [.8, .2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'data'\n",
    "\n",
    "# load dataset\n",
    "data_train = MNIST(\n",
    "    root = datapath,\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    ")\n",
    "data_test = MNIST(\n",
    "    root = datapath, \n",
    "    train = False, \n",
    "    transform = ToTensor(),\n",
    ")\n",
    "data_train, data_val = random_split(data_train, train_val_split, generator=torch.Generator())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation and hyperparameter tuning\n",
    "\n",
    "Once we have assembled our architecture, there are still many aspects that we can fine-tune in order to make it work better.\n",
    "For example, we can change the batch size, learning rate, number of training epochs, or other application-specific hyperparameters.\n",
    "\n",
    "Ideally, we would like to choose the parameters that have the best generalization capability (e.g., we'd like to find a suitable number of epochs so that the model gets properly trained without overfitting).\n",
    "\n",
    "However, we cannot use our test dataset for that. I know it is tempting to do so (and a lot of people out there are doing it). But if you choose the hyperparameters that yield the best performance on the test data, you're essentially using them to \"train\" your model.\n",
    "\n",
    "REMEMBER: You should use your test dataset only to assess your final model. Never touch the test dataset before the model is ready-to-deploy.\n",
    "\n",
    "So, how do we fine-tune our model to reach the best generalization capability?\n",
    "The typical solution is to further split the training data in a training and validation dataset.\n",
    "The validation set is used only to fine-tune hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True, \n",
    "                            pin_memory=True, \n",
    "                            num_workers=2\n",
    "                            )\n",
    "\n",
    "val_loader = DataLoader(data_val, batch_size=32, shuffle=False, \n",
    "                            pin_memory=True, \n",
    "                            num_workers=2\n",
    "                            )\n",
    "\n",
    "test_loader = DataLoader(data_test, batch_size=32, shuffle=False, \n",
    "                            pin_memory=True, \n",
    "                            num_workers=2\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of training dataset:\", len(data_train))\n",
    "print(\"Size of validation dataset:\", len(data_val))\n",
    "print(\"Size of test dataset:\", len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    - input_shape: shape of a single input data point\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, n_classes):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.input_shape = np.asarray(input_shape)\n",
    "        self.n_classes = n_classes\n",
    "        self.seq_model = nn.Sequential(\n",
    "            nn.Linear(self.input_shape.prod(), 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, self.n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_shape.prod())  # make the input of shape (batch_size, height*weight)\n",
    "        logits = self.seq_model(x)\n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMLP(input_shape=(1, 28, 28), n_classes=10).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(data_loader):\n",
    "    n_total = 0\n",
    "    n_correct = 0\n",
    "\n",
    "    for x_batch, y_batch in data_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        logits_batch = model(x_batch)  # model's output scores\n",
    "        n_total += len(y_batch)\n",
    "        n_correct += sum(logits_batch.argmax(axis=-1) == y_batch).item()\n",
    "    return n_correct / n_total\n",
    "\n",
    "print(f\"Train accuracy before training: {model_accuracy(train_loader):.4f}\")\n",
    "print(f\"Test accuracy before training: {model_accuracy(test_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting and early stopping\n",
    "\n",
    "Overfitting is one of the main problems that you will encounter in your deep learning journey.\n",
    "Essentially, we say that a model is \"overfitting\" when it achieve good performance on the training data, but it does not generalize on the validation and test data.\n",
    "\n",
    "When this happens, there are many counter measures that you can take, for example:\n",
    "- Decrease the number of parameters of your model\n",
    "- Insert Dropout layers in your architecture\n",
    "- Use regularization techniques (L1-L2 regularization, batch normalization, weight normalization)\n",
    "- Reduce the number of epochs\n",
    "\n",
    "In particular, a common approach for the last point is to use early stopping.\n",
    "Just as the name says, early stopping consists in interrupting the training process if the model stops improving based on some criterion (typically if the validation loss or accuracy did not improve).\n",
    "\n",
    "Parameters of the early stopping are typically:\n",
    "- `patience`, i.e., how many epochs to wait before deciding to stop training\n",
    "- `min_delta`, a minimum difference between the last recorded best value and the new best value to consider it an improvement (we don't use it in this example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the early stopping parameters\n",
    "patience = 5\n",
    "best_acc_val = 0.0\n",
    "early_stop_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_train = []\n",
    "accuracies_val = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits_batch = model(x_batch)\n",
    "        loss_batch = loss_fn(logits_batch, y_batch)\n",
    "        loss_batch.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    # evaluate the model at the end of each epoch\n",
    "    with torch.no_grad():\n",
    "        acc_train = model_accuracy(train_loader)\n",
    "        acc_val = model_accuracy(val_loader)\n",
    "\n",
    "        print(f\"[Epoch {epoch+1:03d}] train_acc: {acc_train:.3f}, val_acc: {acc_val:.3f}\")\n",
    "\n",
    "        accuracies_train.append(acc_train)\n",
    "        accuracies_val.append(acc_val)\n",
    "\n",
    "        if acc_val > best_acc_val:\n",
    "            best_acc_val = acc_val\n",
    "            early_stop_counter = 0\n",
    "            # save model only if accuracy improved\n",
    "            torch.save(model.state_dict(), f\"saved_models/MLP_GPU_epoch{epoch+1:03d}.pt\")\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f\"Validation accuracy has not improved in {patience} epochs: stop training.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(accuracies_train, '^-', label=\"Training\")\n",
    "plt.plot(accuracies_val, 's-', label=\"Validation\")\n",
    "plt.grid(linestyle=':')\n",
    "plt.ylim([0.8, 1.05])\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train accuracy after training: {model_accuracy(train_loader):.4f}\")\n",
    "print(f\"Test accuracy after training: {model_accuracy(test_loader):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hy673",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "898d28840f55b3c5c9a615fda231169adc20c90e3e87a937f55caa36837c15d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
