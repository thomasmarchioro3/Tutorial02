{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4736e56a10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "datapath = 'data'\n",
    "\n",
    "# load dataset\n",
    "data_train = MNIST(\n",
    "    root = datapath,\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    ")\n",
    "data_test = MNIST(\n",
    "    root = datapath, \n",
    "    train = False, \n",
    "    transform = ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 16\n",
    "lr = 1e-3\n",
    "n_epochs = 100\n",
    "train_val_split = [.8, .2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# torch.Generator() performs a random split, make sure you have set a manual_seed for reproducibility at the beginning of your code\n",
    "# alternatively, you can use torch.Generator().manual_seed(42)\n",
    " \n",
    "data_train, data_val = random_split(data_train, train_val_split, generator=torch.Generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training dataset: 48000\n",
      "Size of validation dataset: 12000\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of training dataset:\", len(data_train))\n",
    "print(\"Size of validation dataset:\", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_sample: torch.Size([1, 28, 28])\n",
      "y_sample is an integer: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "x_sample, y_sample = data_val[0]\n",
    "\n",
    "print(\"Shape of x_sample:\", x_sample.shape)\n",
    "print(\"y_sample is an integer:\", type(y_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(x_sample[0], cmap='binary')\n",
    "plt.title(f'Label: {y_sample: d}')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    - input_shape: shape of a single input data point\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, n_classes):\n",
    "        super().__init__()\n",
    "        self.input_shape = np.asarray(input_shape)\n",
    "        self.n_classes = n_classes\n",
    "        self.seq_model = nn.Sequential(\n",
    "            nn.Linear(self.input_shape.prod(), 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, self.n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_shape.prod())  # make the input of shape (batch_size, height*weight)\n",
    "        scores = self.seq_model(x)\n",
    "        return scores\n",
    "    \n",
    "    # def __repr__(self):\n",
    "    #     return \"Overwritten print\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleMLP(\n",
      "  (seq_model): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=32, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=32, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleMLP(input_shape=(1, 28, 28), n_classes=10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(data_train, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(data_test, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_batch shape: torch.Size([16, 1, 28, 28])\n",
      "y_batch shape: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "x_batch, y_batch = next(iter(train_loader))\n",
    "print(\"x_batch shape:\", x_batch.shape)\n",
    "print(\"y_batch shape:\", y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of model's logits shape: torch.Size([16, 10])\n"
     ]
    }
   ],
   "source": [
    "pred_batch = model(x_batch)\n",
    "print(\"Example of model's logits shape:\", pred_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy before training: tensor(0.0716)\n",
      "Test accuracy before training: tensor(0.0713)\n"
     ]
    }
   ],
   "source": [
    "def model_accuracy(data_loader):\n",
    "    n_total = 0\n",
    "    n_correct = 0\n",
    "\n",
    "    for x_batch, y_batch in data_loader:\n",
    "        logits_batch = model(x_batch)  # model's output scores\n",
    "        n_total += len(y_batch)\n",
    "        n_correct += sum(logits_batch.argmax(axis=-1) == y_batch)\n",
    "    return n_correct / n_total\n",
    "\n",
    "print(\"Train accuracy before training:\", model_accuracy(train_loader))\n",
    "print(\"Test accuracy before training:\", model_accuracy(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:32<00:00,  9.27s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_epochs = 10\n",
    "for _ in tqdm(range(n_epochs)):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits_batch = model(x_batch)\n",
    "        loss_batch = loss_fn(logits_batch, y_batch)\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy after training: tensor(0.9917)\n",
      "Test accuracy after training: tensor(0.9723)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy after training:\", model_accuracy(train_loader))\n",
    "print(\"Test accuracy after training:\", model_accuracy(test_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hy673",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "898d28840f55b3c5c9a615fda231169adc20c90e3e87a937f55caa36837c15d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
